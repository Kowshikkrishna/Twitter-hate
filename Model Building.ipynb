{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_length']=data['tweet'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet=data.tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowshik\\AppData\\Local\\Temp\\ipykernel_21988\\4027588305.py:24: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  punctuation_remove = tweets.str.replace(\"[^a-zA-Z]\", \" \")\n",
      "C:\\Users\\Kowshik\\AppData\\Local\\Temp\\ipykernel_21988\\4027588305.py:27: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  newtweet=punctuation_remove.str.replace(r'\\s+', ' ')\n",
      "C:\\Users\\Kowshik\\AppData\\Local\\Temp\\ipykernel_21988\\4027588305.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  newtweet=newtweet.str.replace(r'^\\s+|\\s+?$','')\n",
      "C:\\Users\\Kowshik\\AppData\\Local\\Temp\\ipykernel_21988\\4027588305.py:33: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  newtweet=newtweet.str.replace(r'\\d+(\\.\\d+)?','numbr')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "stemmer = PorterStemmer()\n",
    "#ff(follow friday)#rt(retweet)Mt(modified tweet)\n",
    "others = [\"#ff\", \"rt\",\"MT\"]\n",
    "#extending stopwords\n",
    "stopwords.extend(others)\n",
    "def preprocess(tweet):  \n",
    "    \n",
    "    # removing extra spaces\n",
    "    ex= re.compile(r'\\s+')\n",
    "    tweet_space = tweet.str.replace(ex, ' ')\n",
    "    \n",
    "    # removing '@'(mentions)\n",
    "    ex = re.compile(r'@[\\w\\-]+')\n",
    "    tweet_name = tweet_space.str.replace(ex, '')\n",
    "    \n",
    "    # removing url's (https://xyz.com)\n",
    "    gex =  re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|' '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    tweets = tweet_name.str.replace(gex, '')\n",
    "    \n",
    "    # removing punctuations and numbers\n",
    "    punctuation_remove = tweets.str.replace(\"[^a-zA-Z]\", \" \")\n",
    "    \n",
    "    # removing whitespace \n",
    "    newtweet=punctuation_remove.str.replace(r'\\s+', ' ')\n",
    "    \n",
    "    # removing leading and trailing whitespace\n",
    "    newtweet=newtweet.str.replace(r'^\\s+|\\s+?$','')\n",
    "    \n",
    "    # replace normal numbers with numbr\n",
    "    newtweet=newtweet.str.replace(r'\\d+(\\.\\d+)?','numbr')\n",
    "    \n",
    "    # lowercasing the tweet\n",
    "    tl = newtweet.str.lower()\n",
    "    \n",
    "    # tokenizing\n",
    "    tokenized_tweet = tl.apply(lambda x: x.split())\n",
    "    \n",
    "    # removing stopwords\n",
    "    tokenized_tweet=  tokenized_tweet.apply(lambda x: [i for i in x if i not in stopwords])\n",
    "    \n",
    "    # stemming of the tweets\n",
    "    tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) \n",
    "    \n",
    "    for i in range(len(tokenized_tweet)):\n",
    "        tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
    "        tp= tokenized_tweet\n",
    "    \n",
    "    return tp\n",
    "\n",
    "processed_tweets = preprocess(tweet)   \n",
    "\n",
    "data['processed_tweets'] = processed_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2),max_df=0.80, min_df=5, max_features=1000)\n",
    "tfidf = tfidf_vectorizer.fit_transform(data['processed_tweets'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf\n",
    "y = data['label'].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy score: 94.521310%\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression().fit(X_train,y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "acc=accuracy_score(y_test,y_preds)\n",
    "print(\"Logistic Regression\")\n",
    "print(\"Accuracy score: %f\"%(acc*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Accuracy Score:51.853590%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y, random_state=42, test_size=0.2)\n",
    "\n",
    "nb=GaussianNB()\n",
    "nb.fit(X_train,y_train)\n",
    "y_preds = nb.predict(X_test)\n",
    "acc2=accuracy_score(y_test,y_preds)\n",
    "print(\"Naive Bayes\")\n",
    "print(\"Accuracy Score:%f\"%(acc2*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_preds = rf.predict(X_test)\n",
    "acc1=accuracy_score(y_test,y_preds)\n",
    "print(\"Random Forest\")\n",
    "print(\"Accuracy score: %f\"%(acc1*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support =LinearSVC(random_state=20)\n",
    "support.fit(X_train,y_train)\n",
    "y_preds = support.predict(X_test)\n",
    "acc3=accuracy_score(y_test,y_preds)\n",
    "print(\"SVM\")\n",
    "print(\"Accuracy Score:%f\"%(acc3*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "objects = ('Logistic', 'RandomForest', 'Naive_bayes', 'SVM')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [acc,acc1,acc2,acc3]\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Algorithm Comparision for F1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps= [('tfidf', TfidfVectorizer(lowercase=True,max_features=1000,stop_words= ENGLISH_STOP_WORDS)),\n",
    "                            ('model',RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(data.processed_tweets,data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.predict(data.processed_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_classification.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(pipeline, filename=\"text_classification.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>text_length</th>\n",
       "      <th>processed_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'buil...</td>\n",
       "      <td>74</td>\n",
       "      <td>cnn call michigan middl school build wall chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
       "      <td>101</td>\n",
       "      <td>comment australia opkillingbay seashepherd hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>retweet if you agree!</td>\n",
       "      <td>22</td>\n",
       "      <td>retweet agre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>@user @user lumpy says i am a . prove it lumpy.</td>\n",
       "      <td>47</td>\n",
       "      <td>lumpi say prove lumpi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>it's unbelievable that in the 21st century we'...</td>\n",
       "      <td>104</td>\n",
       "      <td>unbeliev st centuri need someth like neverump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31934</th>\n",
       "      <td>31935</td>\n",
       "      <td>1</td>\n",
       "      <td>lady banned from kentucky mall. @user  #jcpenn...</td>\n",
       "      <td>59</td>\n",
       "      <td>ladi ban kentucki mall jcpenni kentucki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31946</th>\n",
       "      <td>31947</td>\n",
       "      <td>1</td>\n",
       "      <td>@user omfg i'm offended! i'm a  mailbox and i'...</td>\n",
       "      <td>82</td>\n",
       "      <td>omfg offend mailbox proud mailboxprid liberalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31947</th>\n",
       "      <td>31948</td>\n",
       "      <td>1</td>\n",
       "      <td>@user @user you don't have the balls to hashta...</td>\n",
       "      <td>112</td>\n",
       "      <td>ball hashtag say weasel away lumpi toni dipshit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31948</th>\n",
       "      <td>31949</td>\n",
       "      <td>1</td>\n",
       "      <td>makes you ask yourself, who am i? then am i a...</td>\n",
       "      <td>87</td>\n",
       "      <td>make ask anybodi god oh thank god</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "      <td>67</td>\n",
       "      <td>sikh templ vandalis calgari wso condemn act</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2242 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "13        14      1  @user #cnn calls #michigan middle school 'buil...   \n",
       "14        15      1  no comment!  in #australia   #opkillingbay #se...   \n",
       "17        18      1                             retweet if you agree!    \n",
       "23        24      1    @user @user lumpy says i am a . prove it lumpy.   \n",
       "34        35      1  it's unbelievable that in the 21st century we'...   \n",
       "...      ...    ...                                                ...   \n",
       "31934  31935      1  lady banned from kentucky mall. @user  #jcpenn...   \n",
       "31946  31947      1  @user omfg i'm offended! i'm a  mailbox and i'...   \n",
       "31947  31948      1  @user @user you don't have the balls to hashta...   \n",
       "31948  31949      1   makes you ask yourself, who am i? then am i a...   \n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...   \n",
       "\n",
       "       text_length                                   processed_tweets  \n",
       "13              74  cnn call michigan middl school build wall chan...  \n",
       "14             101  comment australia opkillingbay seashepherd hel...  \n",
       "17              22                                       retweet agre  \n",
       "23              47                              lumpi say prove lumpi  \n",
       "34             104  unbeliev st centuri need someth like neverump ...  \n",
       "...            ...                                                ...  \n",
       "31934           59            ladi ban kentucki mall jcpenni kentucki  \n",
       "31946           82   omfg offend mailbox proud mailboxprid liberalism  \n",
       "31947          112    ball hashtag say weasel away lumpi toni dipshit  \n",
       "31948           87                  make ask anybodi god oh thank god  \n",
       "31960           67        sikh templ vandalis calgari wso condemn act  \n",
       "\n",
       "[2242 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.label == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
